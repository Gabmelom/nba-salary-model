{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_cols = ['name', 'height', 'weight', 'overall', 'position', 'secondary_position']\n",
    "shooting_cols = ['shot_close', 'shot_mid', 'shot_3pt', 'shot_iq', 'free_throw', 'offensive_consistency']\n",
    "inside_scoring_cols = ['driving_layup','standing_dunk','driving_dunk','draw_foul','post_moves','post_hook','post_fade','hands']\n",
    "athleticism_cols = ['speed','acceleration','vertical','strength','stamina','hustle']\n",
    "playmaking_cols = ['speed_with_ball','ball_handle','passing_accuracy','passing_vision','passing_iq']\n",
    "defense_cols = ['interior_defense','perimeter_defense','help_defense_iq','lateral_quickness','pass_perception','steal','block','defensive_consistency']\n",
    "rebounding_cols = ['offensive_rebound','defensive_rebound']\n",
    "potential_cols = ['potential', 'intangibles']\n",
    "\n",
    "cols = ['collection']+ general_cols + shooting_cols + inside_scoring_cols + athleticism_cols + playmaking_cols + defense_cols + rebounding_cols + potential_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get player urls to extract 2k ratings, add urls to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to scrape\n",
    "from time import sleep\n",
    "\n",
    "for year in [20,21,22,23]:\n",
    "    df = pd.DataFrame()\n",
    "    page = 1\n",
    "    while True:\n",
    "        url = f'https://2kdb.net/api/players/{year}/%7B%22freeAgents%22:false,%22page%22:%22{page}%22,%22pageSize%22:%2250%22,%22version%22:%2224%22%7D'\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        data = response.json()\n",
    "        if len(data['players']) == 0:\n",
    "            print(f'Finished scraping 2k{year}, {page} pages & {len(df)} of {data[\"totalPlayers\"]} players scraped.')\n",
    "            break\n",
    "        df = pd.concat([df, pd.DataFrame(data['players'])])\n",
    "        page += 1\n",
    "        sleep(1)\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(f'2k{year}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_100724\\3623435148.py:15: DtypeWarning: Columns (159,163,164,168,171,175,181,185,187,196,199,201,204,213,216,218,221,228,234,240,242) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(data_folder, 'raw','2k ratings', f'2k{year}.csv'))\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_100724\\3623435148.py:15: DtypeWarning: Columns (300) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(data_folder, 'raw','2k ratings', f'2k{year}.csv'))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Collections to keep\n",
    "collections = {\n",
    "    20: '20 Current',\n",
    "    21: '21 Current NBA',\n",
    "    22: '22 NBA: Series 1',\n",
    "    23: '\\'23 NBA: Series 1'\n",
    "}\n",
    "\n",
    "data_folder = os.path.join(os.path.dirname(os.getcwd()), 'data')\n",
    "\n",
    "# Do this for all 2k games\n",
    "for year in collections.keys():\n",
    "    df = pd.read_csv(os.path.join(data_folder, 'raw','2k ratings', f'2k{year}.csv'))\n",
    "\n",
    "    # Keep only the columns we want\n",
    "    df = df.drop(columns=[col for col in df.columns if col not in cols])\n",
    "\n",
    "    # Keep only the rows in the collections we want\n",
    "    df = df[df['collection'] == collections[year]]\n",
    "    df = df.drop(columns=['collection'])\n",
    "\n",
    "    # Aggregate related columns\n",
    "    df['shooting'] = df[shooting_cols].mean(axis=1).astype(int)\n",
    "    df['inside_scoring'] = df[inside_scoring_cols].mean(axis=1).astype(int)\n",
    "    df['athleticism'] = df[athleticism_cols].mean(axis=1).astype(int)\n",
    "    df['playmaking'] = df[playmaking_cols].mean(axis=1).astype(int)\n",
    "    df['defense'] = df[defense_cols].mean(axis=1).astype(int)\n",
    "    df['rebounding'] = df[rebounding_cols].mean(axis=1).astype(int)\n",
    "    df['potential'] = df[potential_cols].mean(axis=1).astype(int)\n",
    "\n",
    "    # Drop the original columns\n",
    "    df = df.drop(columns=shooting_cols + inside_scoring_cols + athleticism_cols + playmaking_cols + defense_cols + rebounding_cols + potential_cols)\n",
    "    \n",
    "    df.to_csv(os.path.join(data_folder, 'clean','2k ratings',f'2k{year}_clean.csv'), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba-salary-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
